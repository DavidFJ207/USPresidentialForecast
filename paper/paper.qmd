---
title: "Forecasting the 2024 US Presidential Election"
subtitle: "Analyzing Demographic Patterns and Predicting Swing States"
author: 
  - Tina Kim
  - David Flores
  - Kevin Shao
thanks: "Code and data are available at: https://github.com/DavidFJ207/USPresidentialForecast"
date: today
date-format: long
abstract: Our analysis of swing state polls for the 2024 U.S. Presidential Election shows a close race. Republicans lead in most key states like Michigan, Georgia, Nevada, Wisconsin, and Pennsylvania, while Democrats have a slight edge in Arizona. The national average also leans Republican, suggesting a Republican win in the 2024 Election.
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(dplyr)
library(knitr)
library(lubridate)
library(ggplot2)
library(ggcorrplot)
library(kableExtra)
library(arrow)
library(zoo)
library(brms)
```

# Introduction

*Overview paragraph:* The 2024 United States of America Presidential Election is to elect the fourty-seventh president of USA, with the two candidates as Donald Trump, the fourty-fifth president of the United States and representative of the Republican Party, and Kamala Harris, current vice president of the United States and representative of the Democratic Party, after Joe Biden announced that he will not continue participate in this presidential election anymore (@BidenQuits). Democracy can be described as liberal and left-leaning, with the emphasis of economy intervention with implementation of policies such as minimum wage and progressive tax rates. Members of the Republican party tend to follow the free economy, and can be described as right-leaning (@RepDem). The results of the 2024 Presidential Election will determine which political party, Republican or Democratic, will become the leader of the United States for the next four years, largely affecting the policies implemented in the United States during this time period. Due to the strong nation power of the United States, this may even affect the world's economic trends in the four years. Therefore, predicting results of the upcoming 2024 United States Presidential Election is a necessary action.

*Estimand paragraph:* To predict results of the 2024 United States of America Presidential Election, our aim is clearly to conclude which candidate, either Harris or Trump, is more likely to win this election. Our response variable is in turn the probability of one candidate winning the election based on poll data, with our chosen poll as Emerson. When the supporting percentage of one candidate, or the party s/he represents, is only slightly less than 50%, we cannot clearly determine whether s/he would be predicted to have been elected as the fourty-seventh US President or not, since there is a group of people who did not choose to participate in the voting process. Therefore, to increase accuracy of predictions, we will build two models, one model with the estimand as the probability of Harris, or the Democratic party, winning the election, and another with the estimand as the probability of Trump, or the Republican party, winning the election. By comparing the two predictions, one can get a final prediction of who is more likely to be elected as the next President of the United States of America.

*Results paragraph:* Summarize the key findings of the model, highlighting its predictive accuracy and implications.

*Why it matters paragraph:* Explain the broader significance of accurately forecasting election results for politics, society, and policymaking.

*Telegraphing paragraph:* 
The remainder of this paper is structured as follows: Section 2 details the data and measurement process; Section 3 covers model development and results; Section 4 discusses implications and future steps.
The remainder of this paper is structured as follows. @sec-data....

<<<<<<< HEAD
# Data {#sec-data}

## Overview
We sourced the "Presidential General Election Polls" dataset from FiveThirtyEight [@FiveThirtyEight2024] and performed an in-depth analysis using the statistical programming language R [@citeR].

Our primary objective was to clean, organize, and analyze U.S. presidential election polling data to provide insights into voter preferences by state. This involved selecting data from reputable pollsters, organizing it by state, and addressing any missing or incomplete entries. Additional datasets were merged where necessary, and after thoroughly addressing missing values, we finalized a polished dataset ready for analysis. Below is a table summarizing the polling data by state, showcasing voter preferences by party and demographic breakdowns. The table highlights key trends and differences across states in terms of party lean and demographic distribution. @fig-predictors-pct-summary provides a snapshot of these findings.
=======

\newpage  
# Data {#sec-data}  
## Overview  
>>>>>>> new-branch-name

```{r}
#| echo: false
#| warning: false
#| message: false

set.seed(754)
poll_data <- read_parquet(here::here(
  "data/02-analysis_data/summarized_state_poll_data.parquet"))
time_data <- read_parquet(here::here(
  "data/02-analysis_data/timeline_data.parquet"))

```

```{r}
#| label: fig-predictors-pct-summary
#| tbl-cap: "Latest Poll Points by Party"
#| echo: false
#| warning: false
#| message: false

# Specify the predictor columns
predictor_columns <- c(
  "What is the highest level of education you have attained? College graduate",
  "What is the highest level of education you have attained? High school or less",
  "Can you please tell me your gender? Female",
  "Can you please tell me your gender? Male",
  "For statistical purposes only, can you please tell me your ethnicity? White or Caucasian",
  "For statistical purposes only, can you please tell me your ethnicity? Hispanic or Latino of any race",
  "Who did you vote for in the 2020 election? Donald Trump",
  "Who did you vote for in the 2020 election? Joe Biden",
  "Do you approve or disapprove of the job Joe Biden is doing as President? Approve",
  "Do you approve or disapprove of the job Joe Biden is doing as President? Disapprove"
)

# Filter poll_data to include only the specified states
poll_summary <- poll_data %>%
  filter(state %in% c("Michigan", "Georgia", "Nevada", "North Carolina", 
                      "New Hampshire", "Wisconsin", "Pennsylvania", "Arizona")) %>%
  group_by(state) %>%   
  summarise(
    dem_total_pct = sum(democrat_pct, na.rm = TRUE),
    rep_total_pct = sum(republican_pct, na.rm = TRUE),
    highly_educated_pct = mean(`What is the highest level of education you have attained? College graduate`, na.rm = TRUE),
    lower_educated_pct = mean(`What is the highest level of education you have attained? High school or less`, na.rm = TRUE),
    female_pct = mean(`Can you please tell me your gender? Female`, na.rm = TRUE),
    male_pct = mean(`Can you please tell me your gender? Male`, na.rm = TRUE),
    non_binary_other_pct = mean(`Can you please tell me your gender? Nonbinary or other`, na.rm = TRUE),
    caucasian_pct = mean(`For statistical purposes only, can you please tell me your ethnicity? White or Caucasian`, na.rm = TRUE),
    minority_pct = 100 - caucasian_pct,
    past_vote_biden = mean(`Who did you vote for in the 2020 election? Joe Biden`, na.rm = TRUE),
    past_vote_trump = mean(`Who did you vote for in the 2020 election? Donald Trump`, na.rm = TRUE)
  ) %>%
  mutate(across(everything(), ~ replace_na(., 0))) %>%  # Replace NA values with 0
  mutate(across(where(is.numeric), ~ round(., 1)))  # Round to the nearest tenth

# Rename columns for clarity
colnames(poll_summary) <- c("State", "Democrat Pct", "Republican Pct", 
                            "High Educated", "Low Educated", "Female", 
                            "Male", "Nonbinary", "Caucasian", 
                            "Minority Ethnicity", "Voted Biden 2020", "Voted Trump 2020")

# Create summary tables
poll_summary_party <- poll_summary %>%
  select(State, `Democrat Pct`, `Republican Pct`, `Voted Biden 2020`, `Voted Trump 2020`)

poll_summary_demographics <- poll_summary %>%
  select(State, `High Educated`, `Low Educated`, `Female`, 
         `Male`, `Nonbinary`, `Caucasian`, `Minority Ethnicity`)

# Display table for party percentages
kable(poll_summary_party) %>%
  kable_styling(font_size = 10, position = "center", full_width = FALSE)

# Display table for demographic variables
kable(poll_summary_demographics) %>%
  kable_styling(font_size = 6, position = "center", full_width = FALSE)

```

We sourced the "Presidential General Election Polls" dataset from FiveThirtyEight [@FiveThirtyEight2024] and analyzed it using the statistical programming language R [@citeR].

Our main goal was to clean, organize, and analyze U.S. presidential election polling data to understand voter preferences by state. We selected data from credible pollsters, sorted it by state, and resolved missing or incomplete entries. Where necessary, we merged additional datasets, ensuring that we carefully handled any gaps in the data. The result was a refined dataset ready for analysis. The table below provides a summary of polling data by state, showing voter preferences by party and various demographics. It highlights key trends and differences across states, focusing on party leanings and demographic splits, as illustrated in @fig-predictors-pct-summary.

## Measurement  
We chose Emerson as our primary pollster, and the reasoning for this is detailed in @sec-appenA. Emerson's polls offered crucial information, such as polling dates, party affiliations, sample sizes, and the percentage of support for each political party.

Our analysis centered on voter preferences by party rather than individual candidates. This approach was more relevant for identifying overall trends and helped us forecast which states might swing in future elections, especially swing states. We will discuss this focus further in our results section, @sec-results.

The Emerson dataset also included valuable demographic data, voting history, and approval ratings. To ensure a consistent analysis, we concentrated on questions that were uniformly asked across all states. This approach allowed us to aggregate and analyze data at the state level without being limited by state-specific polling variations.

## Outcome Variables  
Our initial analysis of the dataset revealed important trends in party preferences across states. In @fig-party-results, we show which states have the strongest leanings toward the Democratic or Republican parties. This visualization is crucial for identifying key swing states, which lie near the center of the graph and show nearly equal support for both parties. These states are especially important for predicting the 2024 election outcome. 

From this analysis, we identified eight critical swing states: Michigan, Georgia, Nevada, North Carolina, New Hampshire, Wisconsin, Pennsylvania, and Arizona. These states will be central to our election prediction. Although Minnesota emerged as a potential swing state, we excluded it due to the wide range of polling data, as explained in @tbl-final-summary. Additionally, we will consider the national average in our overall prediction.
```{r}
#| label: fig-party-results
#| fig-cap: Example Predictor Variable Visualization
#| echo: false
#| warning: false
#| message: false

poll_summary <- poll_data %>%
  group_by(state) %>%   
  summarise(
    dem_total_pct = sum(democrat_pct, na.rm = TRUE),
    rep_total_pct = sum(republican_pct, na.rm = TRUE)
  ) %>%
   mutate(party_diff = dem_total_pct - rep_total_pct)

# Create the vertical bar graph
ggplot(poll_summary, aes(x = party_diff, y = reorder(state, party_diff))) +
  geom_col(aes(fill = party_diff > 0), show.legend = FALSE) +  
  scale_fill_manual(values = c("red", "blue")) +  
  labs(x = "Party Lean (Democrat vs. Republican)", y = "State",
       title = "Party Leaning by State (Democrat vs. Republican)") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6))  

```

```{r}
#| label: tbl-final-summary
#| echo: false
#| warning: false
#| message: false
# Filter time_data for 'DEM' in the 'party' column
dem_data <- time_data %>%
  filter(party == "DEM")

# Calculate 95% confidence interval for each unique state in 'DEM' data
dem_ci_summary <- dem_data %>%
  group_by(state) %>%
  summarise(
    mean_pct = mean(pct, na.rm = TRUE),
    sd_pct = sd(pct, na.rm = TRUE),
    n = sum(!is.na(pct)),
    lower_95 = ifelse(n >= 2, mean_pct - qt(0.975, df = n - 1) * (sd_pct / sqrt(n)), NA),
    upper_95 = ifelse(n >= 2, mean_pct + qt(0.975, df = n - 1) * (sd_pct / sqrt(n)), NA)
  ) %>%
  # Filter out intervals where the bounds go below 40 or above 60, and remove rows where mean_pct exceeds 50
  filter(!(lower_95 < 39 | upper_95 > 60) & mean_pct <= 100)

# Filter time_data for 'REP' in the 'party' column
rep_data <- time_data %>%
  filter(party == "REP")

# Calculate 95% confidence interval for each unique state in 'REP' data
rep_ci_summary <- rep_data %>%
  group_by(state) %>%
  summarise(
    mean_pct = mean(pct, na.rm = TRUE),
    sd_pct = sd(pct, na.rm = TRUE),
    n = sum(!is.na(pct)),
    lower_95 = ifelse(n >= 2, mean_pct - qt(0.975, df = n - 1) * (sd_pct / sqrt(n)), NA),
    upper_95 = ifelse(n >= 2, mean_pct + qt(0.975, df = n - 1) * (sd_pct / sqrt(n)), NA)
  ) %>%
  # Filter out intervals where the bounds go below 40 or above 60, and remove rows where mean_pct exceeds 50
  filter(!(lower_95 < 39 | upper_95 > 60) & mean_pct <= 50)

# Find the intersection of states in both summaries
common_states <- intersect(dem_ci_summary$state, rep_ci_summary$state)

# Filter both summaries to only include the common states
final_dem_ci_summary <- dem_ci_summary %>%
  filter(state %in% common_states)

final_rep_ci_summary <- rep_ci_summary %>%
  filter(state %in% common_states)

# Create the final summary table and round values to 1 decimal point
final_summary_table <- data.frame(
  State = common_states,
  DEM_Mean = round(final_dem_ci_summary$mean_pct, 1),
  DEM_Lower = round(final_dem_ci_summary$lower_95, 1),
  DEM_Upper = round(final_dem_ci_summary$upper_95, 1),
  REP_Mean = round(final_rep_ci_summary$mean_pct, 1),
  REP_Lower = round(final_rep_ci_summary$lower_95, 1),
  REP_Upper = round(final_rep_ci_summary$upper_95, 1)
)

# Print the final summary table using kable
library(knitr)
kable(
  final_summary_table,
  caption = "Final Summary Table of 95% Confidence Intervals for Common States",
  col.names = c("State", "DEM Mean (%)", "DEM Lower 95%", "DEM Upper 95%", "REP Mean (%)", "REP Lower 95%", "REP Upper 95%"),
  format = "markdown"
)


```

```{r}
#| label: fig-party-extremes
#| fig-cap: Demographic Differences Between Top Red and Blue States
#| echo: false
#| warning: false
#| message: false

library(tidyverse)

# Prepare the poll_summary data frame
poll_summary <- poll_data %>%
  mutate(party_diff = democrat_pct - republican_pct) %>%
  select(-c(2, 3, 4, 6, 7, 8, 9, 11)) %>%  # Remove specific columns by index
  select(-contains('Mode')) %>%             # Remove columns containing 'Mode' in their names
  select(-contains('registration')) %>%     # Remove columns containing 'registration' in their names
  drop_na()                                 # Remove rows with any NA values

# Function to identify top N blue and red states
identify_top_states <- function(data, n) {
  data %>%
    arrange(desc(party_diff)) %>%
    summarise(
      blue_states = list(state[1:n]),  
      red_states = list(state[(nrow(data) - n + 1):nrow(data)])
    )
}

# Function to compute mean differences for all numeric variables
compute_mean_differences <- function(data, blue_states, red_states) {
  numeric_vars <- data %>%
    select(-state, -party_diff) %>%
    select(where(is.numeric)) %>%
    names()
  
  blue_means <- data %>%
    filter(state %in% blue_states) %>%
    summarise(across(all_of(numeric_vars), mean, na.rm = TRUE))
  
  red_means <- data %>%
    filter(state %in% red_states) %>%
    summarise(across(all_of(numeric_vars), mean, na.rm = TRUE))
  
  diff_df <- tibble(
    Variable = numeric_vars,
    Blue_Mean = as.numeric(blue_means[1, ]),
    Red_Mean = as.numeric(red_means[1, ]),
    Abs_Difference = abs(Blue_Mean - Red_Mean)
  ) %>%
  filter(!is.na(Blue_Mean) & !is.na(Red_Mean))
  
  diff_df
}

# Function to prepare data for plotting
prepare_plot_data <- function(diff_df, top_n = 6) {
  top_diff_vars <- diff_df %>%
    arrange(desc(Abs_Difference)) %>%
    slice(1:top_n)
  
  top_diff_vars %>%
    pivot_longer(
      cols = c("Blue_Mean", "Red_Mean"), 
      names_to = "Group", 
      values_to = "Mean"
    ) %>%
    mutate(Group = recode(Group, "Blue_Mean" = "Republican State", "Red_Mean" = "Democrat State"))
}

# Function to create the comparison plot
create_comparison_plot <- function(plot_data) {
  ggplot(plot_data, aes(
    x = reorder(Variable, -Mean), 
    y = Mean, 
    fill = Group, 
    label = round(Mean, 1)
  )) +
    geom_col(position = position_dodge(width = 0.9)) +
    geom_text(
      position = position_dodge(width = 0.9), 
      vjust = -0.3, 
      size = 3
    ) +
    # Update the colors and labels for the groups
    scale_fill_manual(values = c("Republican State" = "red", "Democrat State" = "blue")) +
    labs(
      title = "Demographic Differences Between Top Red and Blue States",
      x = "Demographic Variable",
      y = "Mean Percentage",
      fill = "State Group"
    ) +
    scale_y_continuous(limits = c(0, 100)) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 4)
    )
}


# Main analysis function
analyze_state_differences <- function(data, top_n_states = 1, top_n_vars = 4) {
  top_states <- identify_top_states(data, n = top_n_states)
  
  diff_df <- compute_mean_differences(
    data, 
    blue_states = top_states$blue_states[[1]], 
    red_states = top_states$red_states[[1]]
  )
  
  plot_data <- prepare_plot_data(diff_df, top_n = top_n_vars)
  
  plot <- create_comparison_plot(plot_data)
  
  list(
    plot = plot,
    top_variables = diff_df %>% arrange(desc(Abs_Difference)) %>% slice(1:top_n_vars)
  )
}

# Ensure 'state' column exists in poll_summary
if (!"state" %in% colnames(poll_summary)) {
  stop("The 'state' column does not exist in poll_summary.")
}

# Run the analysis
analysis_results <- analyze_state_differences(poll_summary, top_n_states = 1, top_n_vars = 5)

# Display the plot
analysis_results$plot


```
Beyond identifying swing states, it's also important to understand the differences between the strongest Democratic ("blue") and Republican ("red") states. The bar graph in @fig-party-extremes highlights these differences. It focuses on key factors that create the biggest contrasts between Democratic-leaning and Republican-leaning states, helping to show how these factors differ between the most extreme red and blue states. 

To start, the graph features two bars, one for Democratic points and one for Republican points, reflecting the responses to questions asked by Emerson Pollster about voting intentions. These responses closely align with the percentages shown for each state, giving us a clear picture of voter preferences.

The @fig-party-extremes visualization gives us valuable insight into how people’s poll responses may influence their political leanings. 

Through these visualizations, we not only identify which states are most likely to swing in future elections but also better understand the public opinions driving these partisan divides.

## Predictor Variables  

We then take a closer look at the demographic and social factors that shape voter preferences. The predictors we analyze include education levels, gender, and past voting behavior. These variables are important because they significantly impact political leanings and can influence how a state is likely to vote.

```{r}
#| label: updating-predictors
#| echo: false
#| warning: false
#| message: false

column_refs <- list(
  democrat = "democrat_pct",
  republican = "republican_pct",
  highly_educated = "What is the highest level of education you have attained? College graduate",
  lower_educated = "What is the highest level of education you have attained? High school or less",
  female = "Can you please tell me your gender? Female",
  male = "Can you please tell me your gender? Male",
  non_binary_other = "Can you please tell me your gender? Nonbinary or other",
  caucasian = "For statistical purposes only, can you please tell me your ethnicity? White or Caucasian",
  hispanic_latino = "For statistical purposes only, can you please tell me your ethnicity? Hispanic or Latino of any race",
  vote_trump = "Who did you vote for in the 2020 election? Donald Trump",
  vote_biden = "Who did you vote for in the 2020 election? Joe Biden",
  biden_approve = "Do you approve or disapprove of the job Joe Biden is doing as President? Approve",
  biden_disapprove = "Do you approve or disapprove of the job Joe Biden is doing as President? Disapprove",
  previous_vote_trump ="Who did you vote for in the 2020 election? Donald Trump",
  previous_vote_joe ="Who did you vote for in the 2020 election? Joe Biden"

)
```

In @fig-predictors-party-pct, we examine how these factors correlate with party lean across U.S. states. This analysis helps identify which factors have the greatest influence in each state, providing a clearer understanding of what drives voter behavior.

```{r}
#| label: fig-predictors-party-pct
#| fig-cap: Example Predictor Variable Visualization
#| echo: false
#| warning: false
#| message: false

# Calculate poll_summary with rounding to the nearest tenth
poll_summary <- poll_data %>%
  group_by(state) %>%
  summarise(
    dem_total_pct = round(sum(.data[[column_refs$democrat]], na.rm = TRUE), 1),
    rep_total_pct = round(sum(.data[[column_refs$republican]], na.rm = TRUE), 1),
    highly_educated_pct = round(mean(.data[[column_refs$highly_educated]], na.rm = TRUE), 1),
    lower_educated_pct = round(mean(.data[[column_refs$lower_educated]], na.rm = TRUE), 1),
    female_pct = round(mean(.data[[column_refs$female]], na.rm = TRUE), 1),
    male_pct = round(mean(.data[[column_refs$male]], na.rm = TRUE), 1),
    non_binary_other_pct = round(mean(.data[[column_refs$non_binary_other]], na.rm = TRUE), 1),
    caucasian_pct = round(mean(.data[[column_refs$caucasian]], na.rm = TRUE), 1),
    minority_pct = round(100 - caucasian_pct, 1)
  ) %>%
  mutate(party_diff = round(dem_total_pct - rep_total_pct, 1)) %>%
  drop_na()

# Select relevant numeric columns for correlation matrix, excluding PartyDifference
corr_data <- poll_summary %>%
  select(
    Democrat = dem_total_pct,
    Republican = rep_total_pct,
    HighlyEducated = highly_educated_pct,
    LowerEducated = lower_educated_pct,
    Female = female_pct,
    Male = male_pct,
    NonBinary = non_binary_other_pct,
    Caucasian = caucasian_pct,
    Minority = minority_pct
    # No age-related columns included anymore
  )

# Calculate the correlation matrix
cor_matrix <- cor(corr_data, use = "complete.obs")

# Set correlations less than -0.9 to NA
cor_matrix[cor_matrix < -0.9] <- NA

# Visualize the correlation matrix without hierarchical clustering
ggcorrplot(cor_matrix, 
           hc.order = FALSE,  
           type = "lower", 
           lab = TRUE, 
           lab_size = 2,  # Size for correlation labels
           title = "Correlation Matrix of Predictors and Party Lean",
           colors = c("blue", "white", "red"),  
           legend.title = "Correlation") +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),  # Title size and centered
    axis.text = element_text(size = 1),  # Axis text size
    legend.text = element_text(size = 10),  # Legend text size
    legend.title = element_text(size = 10),  # Legend title size
    axis.title = element_text(size = 1)  # Axis labels size
  )
```
  
```{r}
#| label: fig-predictors-party-pct-2
#| fig-cap: Example Voting and Approval Predictor Variable Visualization
#| echo: false
#| warning: false
#| message: false
# Calculate poll_summary with rounding to the nearest tenth
poll_summary_2 <- poll_data %>%
  group_by(state) %>%
  summarise(
    dem_total_pct = round(sum(.data[[column_refs$democrat]], na.rm = TRUE), 1),
    rep_total_pct = round(sum(.data[[column_refs$republican]], na.rm = TRUE), 1),
    vote_trump_pct = round(mean(.data[[column_refs$vote_trump]], na.rm = TRUE), 1),
    vote_biden_pct = round(mean(.data[[column_refs$vote_biden]], na.rm = TRUE), 1),
    biden_approve_pct = round(mean(.data[[column_refs$biden_approve]], na.rm = TRUE), 1),
    biden_disapprove_pct = round(mean(.data[[column_refs$biden_disapprove]], na.rm = TRUE), 1)
  ) %>%
  mutate(party_diff = round(dem_total_pct - rep_total_pct, 1)) %>%
  drop_na()

# Select relevant numeric columns for correlation matrix, excluding PartyDifference
corr_data_2 <- poll_summary_2 %>%
  select(
    Democrat = dem_total_pct,
    Republican = rep_total_pct,
    VotedTrump2020 = vote_trump_pct,
    VotedBiden2020 = vote_biden_pct,
    ApprovesOfBiden = biden_approve_pct,
    DisapprovesOfBiden = biden_disapprove_pct
  )

# Calculate the correlation matrix
cor_matrix_2 <- cor(corr_data_2, use = "complete.obs")

# Set correlations less than -0.9 to NA
cor_matrix_2[cor_matrix_2 < -0.9] <- NA

# Visualize the correlation matrix without hierarchical clustering
ggcorrplot(cor_matrix_2, 
           hc.order = FALSE,  
           type = "lower", 
           lab = TRUE, 
           lab_size = 2,  # Size for correlation labels
           title = "Correlation Matrix of Voting Preferences and State Lean",
           colors = c("blue", "white", "red"),  
           legend.title = "Correlation") +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),  # Title size and centered
    axis.text = element_text(size = 1),  # Axis text size
    legend.text = element_text(size = 10),  # Legend text size
    legend.title = element_text(size = 10),  # Legend title size
    axis.title = element_text(size = 1)  # Axis labels size
  )

```   

```{r}
#| label: fig-predictors-education-race-voting
#| fig-cap: Correlation Matrix of Education, Race, and Past Voting Behavior
#| echo: false
#| warning: false
#| message: false

# Calculate poll_summary with rounding to the nearest tenth
poll_summary_3 <- poll_data %>%
  group_by(state) %>%
  summarise(
    dem_total_pct = round(sum(.data[[column_refs$democrat]], na.rm = TRUE), 1),
    rep_total_pct = round(sum(.data[[column_refs$republican]], na.rm = TRUE), 1),
    highly_educated_pct = round(mean(.data[[column_refs$highly_educated]], na.rm = TRUE), 1),
    lower_educated_pct = round(mean(.data[[column_refs$lower_educated]], na.rm = TRUE), 1),
    caucasian_pct = round(mean(.data[[column_refs$caucasian]], na.rm = TRUE), 1),
    minority_pct = round(100 - caucasian_pct, 1),
    vote_trump_pct = round(mean(.data[[column_refs$vote_trump]], na.rm = TRUE), 1),
    vote_biden_pct = round(mean(.data[[column_refs$vote_biden]], na.rm = TRUE), 1)
  ) %>%
  mutate(party_diff = round(dem_total_pct - rep_total_pct, 1)) %>%
  drop_na()

# Select relevant numeric columns for correlation matrix, excluding PartyDifference
corr_data_3 <- poll_summary_3 %>%
  select(
    Democrat = dem_total_pct,
    Republican = rep_total_pct,
    HighlyEducated = highly_educated_pct,
    LowerEducated = lower_educated_pct,
    Caucasian = caucasian_pct,
    Minority = minority_pct,
    VotedTrump2020 = vote_trump_pct,
    VotedBiden2020 = vote_biden_pct
  )

# Calculate the correlation matrix
cor_matrix_3 <- cor(corr_data_3, use = "complete.obs")

# Set correlations less than -0.9 to NA
cor_matrix_3[cor_matrix_3 < -0.85] <- NA

# Visualize the correlation matrix without hierarchical clustering
ggcorrplot(cor_matrix_3, 
           hc.order = FALSE,  
           type = "lower", 
           lab = TRUE, 
           lab_size = 2,  # Size for correlation labels
           title = "Correlation Matrix of Education, Race, and Past Voting Behavior",
           colors = c("blue", "white", "red"),  
           legend.title = "Correlation") +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),  # Title size and centered
    axis.text = element_text(size = 1),  # Axis text size
    legend.text = element_text(size = 10),  # Legend text size
    legend.title = element_text(size = 10),  # Legend title size
    axis.title = element_text(size = 1)  # Axis labels size
  )

```
<<<<<<< HEAD
The correlation matrix in @fig-predictors-party-pct provides a detailed look at how various predictors are related to party preferences. From this, we can see which predictors—such as education or gender- are more strongly associated with Democratic or Republican leanings. The blue shading indicates stronger correlations with Democratic support, while red represents stronger correlations with Republican support.
=======
>>>>>>> new-branch-name

The correlation matrix in @fig-predictors-party-pct shows how different predictors relate to party preferences. We can see which factors, like education or gender, are more strongly tied to Democratic or Republican leanings. Blue shading indicates stronger Democratic support, while red shows stronger Republican support. Key observations include higher education being linked to Democratic support and lower education favoring Trump in 2020. Minority groups generally lean Democratic, while Caucasian/White voters tend to support Trump. Past voter behavior shows Biden supporters remain Democratic, and Trump supporters disapprove of Biden. Additionally, women lean slightly more Democratic compared to men, who often lean Republican.

```{r}
#| label: fig-points-over-time
#| tbl-cap: "Parties Approval"
#| echo: false
#| warning: false
#| message: false
# Convert `end_date` to Date format, ensure numeric columns, and limit to 2024 and onward
time_data_graph <- time_data %>%
  mutate(
    end_date = as.Date(end_date, format = "%Y-%m-%d"),  # Format matches YYYY-MM-DD
    pct = as.numeric(pct),
    biden_approval = as.numeric(`Do you approve or disapprove of the job Joe Biden is doing as President? Approve`)
  ) %>%
  filter(end_date >= as.Date("2024-01-01"))  # Limit data to 2024 and onward

# Separate data for Democrats, Republicans, and Biden Approval
democrat_data <- time_data_graph %>%
  filter(party == "DEM", !is.na(pct)) %>%
  filter(state == "National", !is.na(pct))

republican_data <- time_data_graph %>%
  filter(party == "REP", !is.na(pct)) %>%
  filter(state == "National", !is.na(pct))

biden_approval <- time_data_graph  %>%
  filter(state == "National", !is.na(pct))%>%
  select(end_date, biden_approval) %>%
  filter(!is.na(biden_approval)) %>%
  distinct()

# Create the time plot with ggplot2
ggplot() +
  # Plot Democrats' pct over time (blue)
  geom_line(data = democrat_data, aes(x = end_date, y = pct, color = "Democrats"), size = 1) +
  
  # Plot Republicans' pct over time (red)
  geom_line(data = republican_data, aes(x = end_date, y = pct, color = "Republicans"), size = 1) +
  
  # Plot Biden's Approval over time (light blue)
  geom_line(data = biden_approval, aes(x = end_date, y = biden_approval, color = "Biden Approval"), size = 1) +
  
  # Add a vertical line for a key date
  geom_vline(xintercept = as.Date("2024-07-21"), color = "red", linetype = "dashed") +
  
  # Customize labels, theme, colors, and y-axis limits
  labs(
    title = "Democrat vs. Republican and Biden Approval Over Time",
    x = "Date",
    y = "Percentage (%)",
    color = "Legend"
  ) +
  scale_color_manual(values = c("Democrats" = "blue", "Republicans" = "red", "Biden Approval" = "lightblue")) +
  ylim(25, 55) + # Set y-axis range from 25 to 55, adjust if needed
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Lastly, we examine Democratic and Republican support alongside Biden's approval over time, marking July 21st when Joe Biden concluded his campaign, as reported by @globalnews2024. During this period, Democratic support was initially low but increased following this change. By analyzing specific demographic factors and previous voting behavior, we aim to predict the 2024 election outcome.

Key predictor variables:

- **Education**: This measures education levels, with higher education often correlating with more Democratic support.
- **Race/Ethnicity**: This examines how different racial and ethnic groups tend to align politically, with minority groups often leaning Democratic and White/Caucasian voters leaning Republican.
- **Gender**: This captures how gender influences party preference, with women generally leaning more Democratic and men more Republican.
- **Priors (Past Voting Behavior)**: This looks at who people voted for in the past, helping us understand ongoing political support or disapproval.
- **Biden's Approval Rating**: This assesses how approval or disapproval of Joe Biden impacts Democratic support, providing insight into shifting voter sentiments.

# Pollster Methodology Overview (Appendix A) {#sec-appenA}  
Append a detailed review of a chosen pollster's methodology, survey techniques, strengths, and weaknesses.

# Model {#sec-model}
## Model Development
<<<<<<< HEAD
The goal of our model is to forecast the popular vote outcome of the 2024 US presidential election, and we will choose the predictor variables based on the the correlation matrix we created previously (@fig-predictors-party-pct). Also, if we choose either the percentage of people who vote for Trump (representing the Republican Party) or Harris (representing the Democratic Party), that number being slightly below 50% does not necessarily means that the corresponding person will not be elected as the next President of the United States, since there is a percentage of people who choose to not vote. Therefore, our final choice is to construct two linear/generalized linear models, one for the percentage that Trump will become the next President and one for Harris respectively. One can then compare the two predicted percentage of people voting for the corresponding President to get the final prediction of who is more likely to be the next President of the United States.

Now we will determine whether to choose generalized linear or linear model for each of the two models by checking the respective normalities of the response variables, which will be the percentage of people supporting the Republican party and the percentage of people supoporting the Democratic party respectively. The following @fig-hist-for-republican is the histogram of the Republican Party Supporting Rate, describing the distribution of the response variable for the first model.

```{r}
#| label: fig-hist-for-republican
#| fig-cap: Distribution of Republican Party Supporting Rate
#| echo: false

# Calculate the variable that represents the Republican Party Supporting Rate
# grouped based on various states
data_rep1 <- poll_data %>%
  group_by(state) %>%
  summarise(
    rep_total_pct = round(sum(.data[[column_refs$republican]], na.rm = TRUE), 1)
  )

# Create a histogram based on targeted data variable
ggplot(data = data_rep1, aes(x=rep_total_pct)) +
  geom_histogram(binwidth = 2) +
  labs(title = "Republic Party Supporting Rate Distirbution", x = "Percentage", y = "Count")

```
And the following @fig-hist-for-democratic is the histogram of the Democratic Party Supporting Rate, describing the distribution of the response variable for the second model.
```{r}
#| label: fig-hist-for-democratic
#| fig-cap: Distribution of Democratic Party Supporting Rate
#| echo: false

# Calculate the variable that represents the Republican Party Supporting Rate
# grouped based on various states
data_rep1 <- poll_data %>%
  group_by(state) %>%
  summarise(
    dem_total_pct = round(sum(.data[[column_refs$democrat]], na.rm = TRUE), 1)
  )

# Create a histogram based on targeted data variable
ggplot(data = data_rep1, aes(x=dem_total_pct)) +
  geom_histogram(binwidth = 2) +
  labs(title = "Democratic Party Supporting Rate Distirbution", x = "Percentage", y = "Count")

```
According to @fig-hist-for-democratic and @fig-hist-for-democratic, both response variables' distributions do not seem to be normal. The distribution of the variable democratic party supporting rate tends to be poisson, since most percentages have a similar frequency, with an outliar at around 67 to 68 percent. The distribution of the variable republic party supporting rate has a maximum frequency at the percentage of around 50 percent, but has similaer frequencies at around 25 to 26 percent and around 48 to 49 percent, which may indicate a violation of the normal distribution property. Therefore, since the response variables of both models are not normally-distributed, a generalized linear model, instead of a linear model, will be used for both models.
=======
>>>>>>> new-branch-name

The goal of our model is to forecast the likely vote outcome in 8 swing states for the 2024 US presidential election. This model will allow us to estimate the expected vote share for each candidate based on state-level characteristics and prior voting patterns, which are especially important in determining close elections.

## Model Set-up

We define the model as a Bayesian linear model where the outcome, \( y_i \), represents the predicted vote share in state \( i \). The predictors in the model capture key demographic and historical voting patterns across swing states, and we aim to model this outcome with an intercept, \( \alpha \), and a state-specific predictor coefficient, \( \beta_i \), that represents the effect of a given variable \( x_i \) on vote share.

### Model Components and Assumptions

- **Outcome Variable:** The predicted vote share (as a percentage) for each candidate in each state.
- **Predictors:** Variables include demographic factors (e.g., education, income, race distribution) and historical voting patterns (e.g., previous election vote shares, approval ratings).
- **Intercept:** Represents the baseline vote share in the absence of additional predictors.
- **Coefficients:** These capture the effect size of each predictor on vote share, allowing for state-specific adjustments.
- **Residual Standard Deviation:** Accounts for unexplained variation in vote share predictions, assumed to follow an exponential distribution.

#### Assumptions
1. **Linearity:** The relationship between each predictor and vote share is assumed to be approximately linear.
2. **Independence:** Vote share predictions for each state are independent, conditional on the predictors.
3. **Normality of Errors:** Errors in vote share predictions are assumed to be normally distributed.
4. **Prior Distributions:** We use weakly informative priors to regularize predictions without imposing strong assumptions.

### Implementation
We run this model in R using the `rstanarm` package, which provides Bayesian estimation with sensible defaults. The default priors in `rstanarm` are chosen to be weakly informative to prevent overfitting while still regularizing our model coefficients.

## Model Justification and Results

By using a Bayesian linear model, we leverage historical and demographic data to provide probabilistic estimates of vote share, giving us a distribution of possible outcomes for each state. This approach allows for uncertainty quantification around predictions, which is particularly important in close elections.

Our results are summarized in Table @tbl-modelresults, which shows the estimated vote shares, posterior means, and credible intervals for each candidate in each swing state. These findings indicate the influence of demographic and historical factors on vote share predictions. Furthermore, the model’s predictive accuracy is evaluated through posterior predictive checks, indicating how well the model captures actual voting patterns. The implications of these findings are significant for forecasting election outcomes, particularly in identifying which states are likely to be more competitive.

```{r}
#| label: fig-results-model
#| tbl-cap: "Forecasting model results based on poll data"
#| echo: false
#| warning: false
#| message: false
# Select relevant columns for the prediction
swing_states <- c("Michigan", "Georgia", "Nevada", "North Carolina", "New Hampshire", "Wisconsin", "Pennsylvania", "Arizona", "National")

# Filter data for the specified swing states and remove any missing data
swing_data <- time_data %>%
  filter(state %in% swing_states, end_date > as.Date("2024-07-21")) %>%
  na.omit()

# Rename columns in swing_data for easier reference
swing_data <- swing_data %>%
  rename(
    `What.is.the.highest.level.of.education.you.have.attained..College.graduate` = "What is the highest level of education you have attained? College graduate",
    `What.is.the.highest.level.of.education.you.have.attained..High.school.or.less` = "What is the highest level of education you have attained? High school or less",
    `Can.you.please.tell.me.your.gender..Female` = "Can you please tell me your gender? Female",
    `Can.you.please.tell.me.your.gender..Male` = "Can you please tell me your gender? Male",
    `For.statistical.purposes.only..can.you.please.tell.me.your.ethnicity..White.or.Caucasian` = "For statistical purposes only, can you please tell me your ethnicity? White or Caucasian",
    `For.statistical.purposes.only..can.you.please.tell.me.your.ethnicity..Hispanic.or.Latino.of.any.race` = "For statistical purposes only, can you please tell me your ethnicity? Hispanic or Latino of any race",
    `Who.did.you.vote.for.in.the.2020.election..Donald.Trump` = "Who did you vote for in the 2020 election? Donald Trump",
    `Who.did.you.vote.for.in.the.2020.election..Joe.Biden` = "Who did you vote for in the 2020 election? Joe Biden",
    `Do.you.approve.or.disapprove.of.the.job.Joe.Biden.is.doing.as.President..Approve` = "Do you approve or disapprove of the job Joe Biden is doing as President? Approve",
    `Do.you.approve.or.disapprove.of.the.job.Joe.Biden.is.doing.as.President..Disapprove` = "Do you approve or disapprove of the job Joe Biden is doing as President? Disapprove"
  )

# Calculate how to distribute the states evenly
num_states <- length(swing_states)
rows_per_state <- floor(nrow(swing_data) / num_states)
extra_rows <- nrow(swing_data) %% num_states

# Create a vector of state names to match the total number of rows
state_vector <- rep(swing_states, each = rows_per_state)
if (extra_rows > 0) {
  state_vector <- c(state_vector, swing_states[1:extra_rows])
}

# Check if the length matches, then assign to swing_data
if (length(state_vector) == nrow(swing_data)) {
  swing_data$State <- state_vector
} else {
  stop("Mismatch between the number of rows in swing_data and the length of state_vector")
}

# Load pre-trained models
bayesian_model_dem <- readRDS(here::here("models/bayesian_model_dem.rds"))
bayesian_model_rep <- readRDS(here::here("models/bayesian_model_rep.rds"))

# Generate predictions for Democratic and Republican models
predictions_dem <- posterior_predict(bayesian_model_dem, newdata = swing_data)
predictions_rep <- posterior_predict(bayesian_model_rep, newdata = swing_data)

# Function to summarize predictions by state
aggregate_summary <- function(predictions, state_labels) {
  summary_df <- data.frame(State = character(), mean = numeric(), lower = numeric(), upper = numeric())
  for (state in unique(state_labels)) {
    state_indices <- which(state_labels == state)
    state_predictions <- predictions[, state_indices]
    state_mean <- mean(state_predictions)
    state_lower <- quantile(state_predictions, 0.025)
    state_upper <- quantile(state_predictions, 0.975)
    summary_df <- rbind(summary_df, data.frame(State = state, mean = state_mean, lower = state_lower, upper = state_upper))
  }
  return(summary_df)
}

# Summarize predictions for both Democrat and Republican models
dem_summary <- aggregate_summary(predictions_dem, swing_data$State)
rep_summary <- aggregate_summary(predictions_rep, swing_data$State)

# Combine summaries into the final prediction summary
prediction_summary <- data.frame(
  State = dem_summary$State,
  DEM_Mean = dem_summary$mean,
  DEM_Lower = dem_summary$lower,
  DEM_Upper = dem_summary$upper,
  REP_Mean = rep_summary$mean,
  REP_Lower = rep_summary$lower,
  REP_Upper = rep_summary$upper
)

```

# Results {#sec-results}

Our results are summarized in @tbl-modelresults.

```{r}
#| label: tbl-modelresults
#| tbl-cap: "Forecasting model results based on poll data"
#| echo: false
#| warning: false
#| message: false

# Modify the prediction summary
prediction_summary <- prediction_summary %>%
  select(State, DEM_Mean, REP_Mean) %>%  # Keep only the mean columns
  mutate(Winner = ifelse(DEM_Mean > REP_Mean, "Democrat", "Republican"))  
# Create a formatted table
kable(
  prediction_summary,
  caption = "Prediction Summary for Swing States with Declared Winner",
  col.names = c("State", "Democrat Points", "Republican Points", "Winner"),
  format = "latex", 
  digits = 2
) %>%
  kable_styling(latex_options = c("striped", "hold_position", "condensed"), 
                full_width = FALSE, 
                font_size = 10)
```
*Person B*: Visualize the model's results and include any performance metrics (e.g., RMSE, test/train split).
```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: ""
#| warning: false

```


# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

Discuss what the model reveals about the election forecast and its potential impact on understanding voting behavior.

*Person C*: Discuss limitations of the model and areas for further improvement.

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

## Appendix A: Pollster Methodology Overview
Emerson College Polling was initially a college polling exercise, and is now an "innovative, nationally-ranked" United States of America polling center (@AboutUs), runned by Emerson college as a non-partisan organization. For the United States 2024 Presidential Election pollster, the Emerson College Polling defined the population to be "likely voters" of 2024 United States Presidential Election. Emerson College Polling does indicate that the targeted population of "likely voters" is based on "2024 Likely Voter Modeling", but the methodology for this modelling and the specific model is not indicated, so the specific validity of the targeted population cannot be determine (@Polling).

Emerson College Polling recruits people completing this survey for the national pollster of the 2024 United States Presidential Election by contacting mobile phones using "MMS-to-Online", "Online Opt-in Panel", and "IVR(Interactive Voice Response)" (@Polling). In the MMS to Online approach, the target population were sent text messages with graphics that invite them to take a "screening questionnaire", and those who pass the questionnaire can move on to take the survey. The selected respondents were based on "state voter files provided by Aristotle." The Online Opt-in Panel approach involves respondents from the targeted population being invited to finish the survey by means of an online opt-in panel "provided by CINT" (@AboutUS). Specifically, in the Online Panel approach, selected voters were pre-matched to "L2 voter file data provided by Rep Data" (@Polling). Finally, the IVR approach involves automatic telephone calls to selected "likely voters", set by target population, and they answer the survey using their "touch-tone telephone". The email approach indicated in Emerson College Polling's official methodology introduction is not mentioned in the National Polling, so it is assumed that this approach is not used in our chosen pollster data.

From the methodology of recruiting people indicated in the previous paragraph, we can see that while the targeted population of the national poll are likely voters, the sampling frame are likely voters that use phones, either mobile or landline. Emerson College Polling chooses 1000 samples from their targeted population, in this case is all likely voters of the 2024 United States Presidential Election, and it is then "weighted by gender, education, race, age, party affiliation, and region based on 2024 likely voter modeling" (@Polling) for each national poll. As most people in the United States use phones by some means, the target population and sampling frame are highly similar, increasing the entire validity of the survey. 

In the "MMS-to-Online" and "IVR(Interactive Voice Response)" approaches, random sampling is used, and in the "Online Opt-in Panel" approach, there is no indication of a specific sampling approach (@AboutUS). We can conclude that the general approach used in this specific pollster is random sampling. Random sampling tends to reduce bias, simplify analysis, and is also easy to implement, but at the same time also requires much time and money. In consideration with the sample size of 1000 people compared to the targeted population of likely voters, which contains most of the population of the United States of America, there is a high possibility of existing selection bias, occurring when the participants are not representative of the population.

There is also no specific indication of how non-response is treated, but the results section of national polls, such as the one from September 29 to October 1, 2024, implicates that non-response are eliminated from final recorded results of the survey. Therefore, we cannot ignore the possibility of non-response bias, occurring when non-respondents differ significantly from respondents.

The questionnaire set by Emerson College Polling for this survey, based on the national polls set from September 29 to October 1, 2024, compose mostly of questions with most common choices listed as choices, and also allowing participants to type in their own answer if it is not included in the list of most common choices. The questionnaire is generally written in an objective voice, and all questions only allow participants to make only one choice. All questions in the questionnaire are relatively-common, including ones about ethnicity, age range, region, and education which collects demographical data, and ones that are related to actual presidential-election predictions, including opinions about Joe Biden's performance, the two main parties (Democratic and Republican), whether s/he would vote, and voting inclinations. The only issue observed in the questionnaire is that it is too lengthy, containing more than 20 questions, which may decrease participants' motivations to complete the survey, even after starting it (@Polling).

Therefore, after analyzing the advantages and disadvantages of this pollster about the 2024 United States Presidential Elections by Emerson College Polling, we can conclude that Emerson College Polling can improve their pollster by implementing the following approaches. Emerson can consider increasing the sample size in order to make their survey more representative of the targeted population, explicitly describing their definition of the targeted population "likely voters" and the model used to determine characteristics of the targeted population. Emerson can also consider changing from simple random to stratified sampling, based on different states or other demographical features based on their targeted population model, making their sample more representative of the population, decrease the length of the questionnaire, and also explicitly explain their treatment of non-response, which will increase the validity of the study. Overall, this pollster is still highly valid, and generally reliable for predicting the 2024 United States Presidential Election.

## Appendix B: Idealized Survey Design for $100K Budget
*Person C*: Develop and describe an ideal survey design for forecasting the election with a $100K budget, and include survey link.

Sampling approach: The sampling approach we will use is stratified random sampling where we divide the population into strata based on.... (age, gender, education level, etc.)
Recruit Respondents: We will recruit respondents using an online survey on Google Forms so that we can minimize the cost and maximize the range of respondents we can reach. We will spend a portion of our budget (specify here) to advertise these surveys and also send out emails, with an additional monetary incentive (specify here) to encourage more participation. 
Data validation: IP address tracking to prevent duplicate responses.
Poll Aggregation: Incorporate Bayesian Inference.

Survey Link: (Short questionnaire asking for demographic questions to be added here)
Copy of Survey: 

## Additional Data & Model Details
Include any technical details on data cleaning, model diagnostics, and posterior checks.



# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

```


\newpage


# References


